{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLClass. \"Прикладной анализ данных\"\n",
    "# Модуль \"Машинное обучение с помощью Python\"\n",
    "<img src=\"../img/mlclass_logo.jpg\" height=\"240\" width=\"240\">\n",
    "## Авторы материала: преподаватель ФКН НИУ ВШЭ Кашницкий Юрий, магистрант ВМК МГУ Евгений Колмаков\n",
    "Материал распространяется на условиях лицензии <a href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-Share Alike 4.0</a>. Можно использовать в любых целях, но с обязательным упоминанием автора курса и аффилиации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Урок 6. Нейронные сети. Бустинг. Смешивание алгоритмов. Стекинг.\n",
    "## Часть 3. Ансамбли алгоритмов в задачах Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При решении задач Kaggle наиболее простым способом аггрегирования алгоритмов является построение ансамбля с использованием только результатов работы алгоритмов на тестовой выборке. При таком подходе отпадает необходимость в обучении новой модели, задача сводится к композиции векторов ответов построенных ранее алгоритмов. Например, это может быть использовано при командной работе: каждый член команды обучает свой алгоритм, с помощью него делает предсказания на тестовой выборке, после чего полученные векторы предсказаний аггрегируются некоторым образом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Голосование (voting)\n",
    "\n",
    "Простейшим способом композиции ответов нескольких классификаторов является (взвешенное) голосование. Обучим 3 разных по природе классификатора: Random Forest, RBF-SVM и kNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import sys\n",
    "if sys.version_info.major == 2:\n",
    "    from urllib import urlopen\n",
    "elif sys.version_info.major == 3:\n",
    "    from urllib.request import urlopen\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/\"+\\\n",
    "        \"pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "raw_data = urlopen(url)\n",
    "data = np.loadtxt(raw_data, delimiter=\",\")\n",
    "\n",
    "X = data[:, :8]\n",
    "y = data[:, 8]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=2).fit(X_train, y_train)\n",
    "svm = SVC(C=5.0, gamma=0.001).fit(X_train, y_train)\n",
    "knn = KNeighborsClassifier(n_neighbors=15).fit(X_train, y_train)\n",
    "\n",
    "np.savetxt(\"rf.csv\", rf.predict(X_test), delimiter=\",\", fmt=\"%d\")\n",
    "np.savetxt(\"svm.csv\", svm.predict(X_test), delimiter=\",\", fmt=\"%d\")\n",
    "np.savetxt(\"knn.csv\", knn.predict(X_test), delimiter=\",\", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве меры качества возьмем AUC. Рассмотрим простое и взвешенное голосование. \"Голос\" лучшего из трех классификаторов будем считать за два - это помогает в борьбе с тем, что плохие классификаторы сильно \"тянут\" меру качества вниз. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF AUC =  0.69178468259\n",
      "SVM AUC =  0.730853237511\n",
      "kNN AUC =  0.724476854788\n",
      "Simple voting AUC =  0.727753117734\n",
      "Weighted voting AUC =  0.746353836398\n",
      "Simple SVM & kNN voting AUC =  0.752554075953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rfg_pred = np.loadtxt(\"rf.csv\", delimiter=\",\")\n",
    "svm_pred = np.loadtxt(\"svm.csv\", delimiter=\",\")\n",
    "knn_pred = np.loadtxt(\"knn.csv\", delimiter=\",\")\n",
    "\n",
    "print(\"RF AUC = \", roc_auc_score(y_test, rfg_pred))\n",
    "print(\"SVM AUC = \", roc_auc_score(y_test, svm_pred))\n",
    "print(\"kNN AUC = \", roc_auc_score(y_test, knn_pred))\n",
    "\n",
    "# Simple voting\n",
    "voting_pred = ((rfg_pred + svm_pred + knn_pred) >= 2).astype(int)\n",
    "print(\"Simple voting AUC = \", roc_auc_score(y_test, voting_pred))\n",
    "\n",
    "# SVM has the best accuracy, so we count its vote as two\n",
    "wvoting_pred = ((rfg_pred + 2 * svm_pred + knn_pred) >= 2).astype(int)\n",
    "print(\"Weighted voting AUC = \", roc_auc_score(y_test, wvoting_pred))\n",
    "\n",
    "# Simple voting between two best \n",
    "two_best_voting_pred = ((svm_pred + knn_pred) >= 1).astype(int)\n",
    "print(\"Simple SVM & kNN voting AUC = \", \n",
    "      roc_auc_score(y_test, two_best_voting_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "2_1_7_regul.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
